#!/usr/bin/env python3

import os
import io
import re
import argparse
import itertools
import collections as col
import operator as op
import pickle as pck

import pandas as pd


def parse_args():
    parser = argparse.ArgumentParser()
    parser.add_argument(
        '--agp-file',
        '-a',
        type=str,
        dest='agp',
        help='AGP assembly layout file generated by Bionano tool set for hybrid assembly.'
    )
    parser.add_argument(
        '--fasta-file',
        '-f',
        type=str,
        dest='fasta',
        help='FASTA file containig scaffold sequences generated by Bionano tool set for hybrid assembly.'
    )
    parser.add_argument(
        '--dummy-fasta',
        '-d',
        type=str,
        dest='dummy',
        help='FASTA sequence for dummy contig used to avoid empty output files.'
    )
    parser.add_argument('--no-fasta-cache', action='store_true', default=False, dest='no_fasta_cache')
    parser.add_argument(
        '--bed-file',
        '-b',
        type=str,
        dest='bed',
        help='Contig-to-reference alignments (unfiltered) of original contigs used as input to hybrid scaffolding.'
    )
    parser.add_argument(
        '--assembly-index',
        '-fai',
        type=str,
        dest='index',
        help='FASTA index file of original assembly, used to verify scaffolded contig length.'
    )
    parser.add_argument(
        '--output',
        '-o',
        type=str,
        dest='output',
        help='Specify output prefix (directories will be created). Default: $PWD/bng_hybrid',
        default=os.path.join(os.getcwd(), 'bng_hybrid')
    )
    args = parser.parse_args()
    return args


def compute_scaffold_layout(agp_layout, fasta_seqs, layout_cache):

    if layout_cache is None:
        fasta_layout = compute_scaffold_sequence_stats(agp_layout, fasta_seqs)
    else:
        if os.path.isfile(layout_cache):
            with pd.HDFStore(layout_cache, 'r') as hdf:
                fasta_layout = hdf['/cache']
        else:
            fasta_layout = compute_scaffold_sequence_stats(agp_layout, fasta_seqs)
            with pd.HDFStore(layout_cache, 'w') as hdf:
                hdf.put('cache', fasta_layout, format='fixed')
    return fasta_layout


def match_agp_to_fasta(agp_row, sequence_part):

    get_nuc_counts = op.itemgetter(*('A', 'C', 'G', 'T', 'a', 'c', 'g', 't', 'N', 'n'))

    orient_map = {
        '+': 1,
        '-': -1
    }

    seq_stats = col.Counter(sequence_part)
    if agp_row['comp_type'] == 'N':
        # inserted sequence gap
        entity = (
            agp_row['object_name'],
            'gap',
            agp_row['comp_number'],
            agp_row['object_start'] - 1,
            agp_row['object_end'],
            int(agp_row['comp_name_OR_gap_length']),
            0,  # orientation
            'gap',
            -1,  # component start, end, complete
            -1,
            -1,
            *get_nuc_counts(seq_stats)
        )
    elif agp_row['comp_type'] == 'W':
        # assembled WGS contig
        contig_name = agp_row['comp_name_OR_gap_length']
        if '_subseq_' in contig_name:
            contig_name, subseq = contig_name.split('_subseq_')
            start, end = subseq.split(':')
            start = int(start) - 1
            end = int(end)
        else:
            start = 0
            end = len(sequence_part)
        orientation = orient_map[agp_row['comp_orient_OR_linkage_evidence']]
        complete = 1 if (end - start) == len(sequence_part) else 0

        comp_length = agp_row['object_end'] - (agp_row['object_start'] - 1)
        assert comp_length == len(sequence_part) == (end - start), \
            'Length mismatch: {} / {} / {}'.format(comp_length, len(sequence_part), end - start)

        entity = (
            agp_row['object_name'],
            'sequence',
            agp_row['comp_number'],
            agp_row['object_start'] - 1,
            agp_row['object_end'],
            (end - start),
            orientation,
            contig_name,
            start,
            end,
            complete,
            *get_nuc_counts(seq_stats)

        )

    else:
        raise ValueError('Unexpected component type: {}'.format(agp_row))

    return entity


def compute_scaffold_sequence_stats(agp_layout, fasta_seqs):

    get_nuc_counts = op.itemgetter(*('A', 'C', 'G', 'T', 'a', 'c', 'g', 't', 'N', 'n'))

    scaffold_idx = agp_layout['object_name'].str.match('Super-Scaffold')
    scaffolds = sorted(set(agp_layout.loc[scaffold_idx, 'object_name'].values))

    fasta_entities = []

    for scf in scaffolds:
        scf_seq = fasta_seqs[scf]
        seq_stats = col.Counter(scf_seq)

        fasta_entities.append(
            (
                'scaffold',
                'self',
                0,
                0,
                len(scf_seq),
                len(scf_seq),
                0,
                scf,
                0,
                len(scf_seq),
                1,
                *get_nuc_counts(seq_stats)
            )
        )

        for idx, row in agp_layout.loc[agp_layout['object_name'] == scf, :].iterrows():
            row_entity = match_agp_to_fasta(row, scf_seq[row['object_start']-1:row['object_end']])
            fasta_entities.append(row_entity)

    df = pd.DataFrame.from_records(
        fasta_entities,
        columns=[
            'object',
            'component',
            'order',
            'start',
            'end',
            'length',
            'orientation',
            'name',
            'component_start',
            'component_end',
            'component_complete',
            'A', 'C', 'G', 'T', 'a', 'c', 'g', 't', 'N', 'n'
        ]
    )
    return df


def load_assembly_contig_sizes(file_path):

    columns = ['contig_name', 'contig_size']

    df = pd.read_csv(
        file_path,
        sep='\t',
        header=None,
        names=columns,
        usecols=columns,
        index_col=None
    )
    return df


def read_fasta_file(fasta_path):

    current_scf = None
    current_seq = ''

    seq_store = dict()

    with open(fasta_path, 'r') as fasta:
        for line in fasta:
            if line.startswith('>'):
                if current_scf is not None:
                    seq_store[current_scf] = current_seq
                current_seq = ''
                scaffold = line.strip().strip('>')
                current_scf = scaffold
                continue
            current_seq += line.strip()
    
    if current_seq:
        seq_store[current_scf] = current_seq

    return seq_store


def load_fasta_scaffolds(fasta_path, seq_cache):

    if seq_cache is None:
        seq_store = read_fasta_file(fasta_path)
    else:
        if os.path.isfile(seq_cache):
            with open(seq_cache, 'rb') as cache:
                seq_store = pck.load(cache)
        else:
            seq_store = read_fasta_file(fasta_path)
            with open(seq_cache, 'wb') as cache:
                pck.dump(seq_store, cache)

    return seq_store


def fill_in_gap_coordinates(fasta_layout):

    rows = []
    starts = []
    ends = []

    for idx in fasta_layout.loc[fasta_layout['component'] == 'gap', :].index.values:
        rows.append(idx)
        starts.append(fasta_layout.at[idx-1, 'end'])
        ends.append(fasta_layout.at[idx+1, 'start'])

    fasta_layout.loc[rows, 'start'] = starts
    fasta_layout.loc[rows, 'end'] = ends
    
    return fasta_layout


def parse_agp_layout(agp_path):

    agp_header = [
        'object_name',
        'object_start',
        'object_end',
        'comp_number',
        'comp_type',
        'comp_name_OR_gap_length',
        'comp_start_OR_gap_type',
        'comp_end_OR_linkage',
        'comp_orient_OR_linkage_evidence'
    ]

    df = pd.read_csv(agp_path, sep='\t', comment='#', names=agp_header)
    # hopfully, all AGP files are simple in structure
    assert len(set(df['comp_type'].values).union(set(['W', 'N']))) == 2, 'Unexpected component type'
    assert df['comp_end_OR_linkage'].str.match('([0-9]+|yes)').all(), 'Unexpected linkage type'
    assert df['comp_start_OR_gap_type'].str.match('([0-9]+|scaffold)').all(), 'Unexpected gap type'
    return df


def compute_bng_contig_support(agp_layout):

    supported = []
    unsupported = []
    contig_names = []

    contig_to_scaffold = col.defaultdict(list)
    scaffold_to_contig = col.defaultdict(list)

    unsupported_broken = col.Counter()

    for idx, row in agp_layout.iterrows():
        if row['comp_type'] == 'N':
            continue
        else:
            contig_name = row['comp_name_OR_gap_length']
            if 'subseq' in contig_name:
                contig_name = contig_name.split('_subseq_')[0]

            if 'Super-Scaffold' not in row['object_name']:
                # unscaffolded sequence
                if 'subseq' in row['comp_name_OR_gap_length']:
                    # happens that multiple fragments of a contig
                    # appear as unsupported / unscaffolded for
                    # whatever reason
                    unsupported_broken[contig_name] += 1

                supported.append(0)
                unsupported.append(int(row['comp_end_OR_linkage']))
            else:
                contig_to_scaffold[contig_name].append(row['object_name'])
                scaffold_to_contig[row['object_name']].append(contig_name)

                supported.append(int(row['comp_end_OR_linkage']))
                unsupported.append(0)

            contig_names.append(contig_name)

    df = pd.DataFrame(
        [contig_names, supported, unsupported],
        index=[
            'contig_name',
            'BNG_supported',
            'BNG_unsupported'
        ]
    )
    df = df.transpose()

    contig_counts = df['contig_name'].value_counts()
    df = df.groupby('contig_name')[['BNG_supported', 'BNG_unsupported']].sum()
    df['contig_name'] = df.index.values
    df.reset_index(drop=True, inplace=True)
    df['contig_breaks'] = df['contig_name'].apply(lambda x: contig_counts[x] - 1)

    # no clue why, but some contigs are broken despite being unsupported
    # cluster10_contig_270_subseq_1:79636_obj
    # cluster10_contig_270_subseq_79637:120374_obj
    # ---> cluster10_contig_270    120374
    # so fix that here
    df.loc[df['BNG_supported'] == 0, 'contig_breaks'] = 0

    # now fix cases where a single contig has several BNG unsupported
    # fragments, which would otherwise be counted multiple times
    for ctg, broken_count in unsupported_broken.most_common():
        if broken_count < 2:
            break
        # count several "unsupported" fragments as one
        unsupported_breaks = broken_count - 1
        counted_breaks = int(df.loc[df['contig_name'] == ctg, 'contig_breaks'])
        if counted_breaks > 0:
            # avoids clash/duplicates together with first fix
            df.loc[df['contig_name'] == ctg, 'contig_breaks'] -= unsupported_breaks

    return df, contig_to_scaffold, scaffold_to_contig


def parse_contig_alignments(bed_path):

    bed_columns = [
        'chrom',
        'start',
        'end',
        'contig',
        'mapq',
        'strand'
    ]

    df = pd.read_csv(bed_path, sep='\t', names=bed_columns, header=None)
    df['chrom'] = df['chrom'].apply(lambda x: x.split('_')[0])

    df['length'] = df['end'] - df['start']
    df['cluster'] = df['contig'].apply(lambda x: x.split('_')[0])

    chrom_cluster_match = df.groupby(['chrom', 'cluster', 'mapq'])['length'].sum()
    chrom_cluster_match.sort_values(ascending=False, inplace=True)

    return df, chrom_cluster_match


def alignments_per_scaffold(contig_to_scaffold, aln_view, contig_view):

    # give bonus for contigs that have no breaks
    # and that are fully supported by Bionano
    select_nobreak = contig_view['contig_breaks'] == 0
    select_support = contig_view['BNG_unsupported'] == 0

    # this is currently not used
    good_contigs = set(contig_view.loc[select_nobreak & select_support, 'contig_name'])

    alignments_per_scaffold = col.defaultdict(col.Counter)

    for contig, scaffolds in contig_to_scaffold.items():
        for s in scaffolds:
            contig_align = aln_view.loc[aln_view['contig'] == contig, :].groupby(['chrom', 'mapq'])['length'].sum()
            if contig_align.empty:
                alignments_per_scaffold[s][('unaln', 0)] = 0
            for idx, sum_len in contig_align.iteritems():
                alignments_per_scaffold[s][idx] += sum_len

    # TODO do this directly in pandas DF

    # compute scaffold to chromosome assignment confidences
    # as weighted average alignment length between the two

    scaffold_chrom_match = dict()

    for scaffold, alignments in alignments_per_scaffold.items():
        # consider X, Y as single entity
        # and skip over chrUn
        count_align = col.Counter()
        for (chrom, mapq), length in alignments.items():
            if chrom == 'chrUn':
                continue
            if mapq == 0:
                continue
            elif chrom in ['chrX', 'chrY']:
                count_align['chrXY'] += length * mapq
            else:
                count_align[chrom] += length * mapq

        total_align = sum(count_align.values())
        try:
            best_match, best_align = count_align.most_common(1)[0]
        except IndexError:
            # in cases where the only recorded alignment is to
            # an unplaced chromosome, this happens
            best_match = 'random'
            confidence = 0.0
        else:
            confidence = round(best_align / total_align, 3)
        scaffold_chrom_match[scaffold] = best_match, confidence

    return scaffold_chrom_match


def classify_contig_breaks(contig_view, contig_to_scaffold, scaffold_to_chrom):

    contig_view['local_breaks'] = 0  # broken, same scaffold
    contig_view['global_breaks'] = 0  # broken, same chromosome
    contig_view['chimeric_breaks'] = 0  # broken, different chromosome
    contig_view['support_breaks'] = 0  # broken, partially unsupported by BNG
    
    # easy case: part of contig has no BNG support
    select_broken = (contig_view['BNG_supported'] > 0) & (contig_view['BNG_unsupported'] > 0)
    contig_view.loc[select_broken, 'support_breaks'] = 1

    for idx, row in contig_view.loc[contig_view['contig_breaks'] > 0, :].iterrows():
        if row['contig_breaks'] == row['support_breaks']:
            continue
        scaffolds = contig_to_scaffold[row['contig_name']]

        if len(scaffolds) == 1:
            # must be single local / within-scaffold misassembly
            contig_view.loc[idx, 'local_breaks'] += 1
            continue

        # several local breaks
        scaffold_counts = col.Counter(scaffolds)
        for name, count in scaffold_counts.most_common():
            if count < 2:
                break
            # must be local break
            contig_view.loc[idx, 'local_breaks'] += (count - 1)

        if len(set(scaffolds)) > 1:
            try:
                scaffold_chroms = [(s, scaffold_to_chrom[s]) for s in scaffolds]
            except KeyError:
                print(row)
                print(scaffolds)
                raise
            global_breaks = 0
            chimeric_breaks = 0
            local_breaks = contig_view.loc[idx, 'local_breaks']
            remaining_breaks = row['contig_breaks'] - row['support_breaks'] - local_breaks
            scored = set()
            for a, b in itertools.combinations(scaffold_chroms, 2):
                if remaining_breaks == 0:
                    # this condition is needed for cases where a single
                    # contig is scattered across several chromosomes,
                    # and we only want to count this as one chimeric break
                    break
                if (a, b) in scored or (b, a) in scored:
                    continue
                (a_scf, a_chr), (b_scf, b_chr) = a, b
                if a_scf == b_scf:
                    scored.add((a, b))
                    scored.add((b, a))
                    # local breaks covered above
                    continue
                
                if a_chr == b_chr:
                    scored.add((a, b))
                    scored.add((b, a))
                    global_breaks += 1
                    remaining_breaks -= 1
                else:
                    scored.add((a, b))
                    scored.add((b, a))
                    chimeric_breaks += 1
                    remaining_breaks -= 1

            contig_view.loc[idx, 'global_breaks'] += global_breaks
            contig_view.loc[idx, 'chimeric_breaks'] += chimeric_breaks

    # check that all breaks are accounted for
    break_counts = contig_view[
        [
            'local_breaks',
            'global_breaks',
            'chimeric_breaks',
            'support_breaks'
        ]
    ].sum(axis=1)

    mismatched = contig_view['contig_breaks'] != break_counts

    if mismatched.any():
        subset = contig_view.loc[mismatched, :]
        raise ValueError('Unaccounted contig breaks: {}'.format(subset))

    contig_view.sort_values(['BNG_supported', 'BNG_unsupported'], inplace=True, ascending=False)

    return contig_view


def assign_chrom_to_scaffolds(fasta_layout, scaffold_to_chrom):

    chrom_conf_columns = []
    for idx, row in fasta_layout.iterrows():
        if 'Scaffold' in row['object']:
            values = scaffold_to_chrom[row['object']]
        elif 'Scaffold' in row['name']:
            values = scaffold_to_chrom[row['name']]
        else:
            raise ValueError('{} / {}'.format(idx, row))
        chrom_conf_columns.append(values)

    add_info = pd.DataFrame(
        chrom_conf_columns,
        columns=['chrom', 'confidence'],
        index=fasta_layout.index
    )

    fasta_layout = pd.concat([fasta_layout, add_info], axis=1)

    return fasta_layout


def load_dummy_fasta(dummy_path):

    seq = ''
    with open(dummy_path, 'r') as fasta:
        for line in fasta:
            if line.startswith('>'):
                continue
            seq += line.strip()
    return seq


def dump_fasta_sequences(fasta_layout, fasta_seqs, dummy_fasta, fasta_out):

    fasta_layout.loc[fasta_layout['confidence'] < 0.5, 'chrom'] = 'chrUn'

    dummy_sequence = load_dummy_fasta(dummy_fasta)

    dump_groups = fasta_layout.loc[fasta_layout['object'] == 'scaffold', ].groupby(['name', 'chrom'])['length'].sum()
    
    chroms = sorted(set(dump_groups.index.get_level_values('chrom')))

    scaffold_out = fasta_out + '.scaffolds.wg.fasta'
    with open(scaffold_out, 'w'):
        pass

    contig_seqs = fasta_layout['component'] == 'sequence'

    for c in chroms:
        chrom_contig_out = fasta_out + '.contigs.{}.fasta'.format(c)

        with open(chrom_contig_out, 'w') as dump:

            for scaffold, length in dump_groups.xs(c, level='chrom').items():
                coord = 'scf:0-{}'.format(length)
                scaffold_header = '@'.join([scaffold, c, coord])
                scaffold_seq = fasta_seqs[scaffold]
                with open(scaffold_out, 'a') as scaffold_dump:
                    write_fasta(scaffold_header, scaffold_seq, scaffold_dump)
                
                scaffold_contigs = fasta_layout['object'] == scaffold

                for idx, row in fasta_layout.loc[contig_seqs & scaffold_contigs, :].iterrows():
                    coord = 'ctg:{}-{}'.format(row['component_start'], row['component_end'])
                    orient = 'frw' if int(row['orientation']) == 1 else 'rev'
                    contig_name = row['name']
                    header = '@'.join([scaffold, c, str(row['order']), orient, contig_name, coord])
                    contig_seq = scaffold_seq[row['start']:row['end']]
                    write_fasta(header, contig_seq, dump)
    
    # this is just to comply with Snakemake's requirement;
    # ensure that all possible output files do exist
    possible_outputs = ['chr' + str(i) for i in range(1, 23)] + ['chrXY', 'chrUn']
    for c in possible_outputs:
        chrom_contig_out = fasta_out + '.contigs.{}.fasta'.format(c)
        if not os.path.isfile(chrom_contig_out):
            with open(chrom_contig_out, 'w') as dump:
                header = 'dummy'
                write_fasta(header, dummy_sequence, dump)

    return


def write_fasta(header, sequence, output):

    line_length = 120

    chars_written = 0

    _ = output.write('>{}\n'.format(header))

    for pos in range(len(sequence) // line_length + 1):
        start = pos * line_length
        end = start + line_length
        chars_written += output.write(sequence[start:end])
        _ = output.write('\n')

    if not chars_written == len(sequence):
        raise ValueError('Dropped sequence during out dump: {} / {}'.format(chars_written, len(sequence)))
    _ = output.write('\n')
    return


def dump_statistics(fasta_layout, contig_view, output):

    output_layout = output + '.scaffold-layout.tsv'
    output_contigs = output + '.contig-stats.tsv'

    for df, outfile in zip([fasta_layout, contig_view], [output_layout, output_contigs]):
        df.to_csv(
            outfile,
            sep='\t',
            mode='w',
            index=False,
            header=True
        )
    return


def check_contig_sizes(contig_view, index_view):

    if contig_view.shape[0] != index_view.shape[0]:
        # cannot be compatible
        index_contigs = set(index_view['contig_name'].values)
        scaffold_contigs = set(contig_view['contig_name'].values)
        problem_contigs = index_contigs.symmetric_difference(scaffold_contigs)
        raise ValueError('Unshared contigs: {}'.format(sorted(problem_contigs)))

    tmp = contig_view.merge(index_view, on='contig_name')
    tmp['diff'] = tmp['contig_size'] - tmp['BNG_unsupported'] - tmp['BNG_supported']

    tmp = tmp.loc[tmp['diff'] != 0, :].copy()
    if not tmp.empty:
        raise ValueError('Contig sizes between scaffolds and original assembly differ:\n{}'.format(tmp))
    return


def main():
    args = parse_args()

    out_dirs = os.path.dirname(os.path.abspath(args.output))
    os.makedirs(out_dirs, exist_ok=True)

    seq_cache = args.output + '.cache.seqs.pck'
    layout_cache = args.output + '.cache.layout.h5'

    if args.no_fasta_cache:
        seq_cache = None
        layout_cache = None

    agp_layout = parse_agp_layout(args.agp)
 
    # load (and cache) input FASTA scaffold
    fasta_seqs = load_fasta_scaffolds(args.fasta, seq_cache)

    fasta_layout = compute_scaffold_layout(
        agp_layout,
        fasta_seqs,
        layout_cache
    )
        
    aln_view, chrom_cluster_match = parse_contig_alignments(args.bed)

    # compute BNG support and number of breaks (uncategorized) per contig
    contig_view, contig_to_scaffold, scaffold_to_contig = compute_bng_contig_support(agp_layout)

    # load contig sizes of original assembly for sanity checking
    # prevent sequence mix-ups
    fasta_idx = load_assembly_contig_sizes(args.index)

    _ = check_contig_sizes(contig_view, fasta_idx)

    scaffold_to_chrom = alignments_per_scaffold(
        contig_to_scaffold,
        aln_view, 
        contig_view,
    )

    contig_view = classify_contig_breaks(contig_view, contig_to_scaffold, scaffold_to_chrom)
    fasta_layout = assign_chrom_to_scaffolds(fasta_layout, scaffold_to_chrom)

    _ = dump_fasta_sequences(fasta_layout, fasta_seqs, args.dummy, args.output)

    _ = dump_statistics(fasta_layout, contig_view, args.output)

    return 0


if __name__ == '__main__':
    main()
