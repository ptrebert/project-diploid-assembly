{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FTP FASTQ libs:  2304\n",
      "OK libs  1540\n",
      "Blacklist  764\n",
      "100c controls:  24\n",
      "-- in AS list:  ['HG03009x02PE20386']\n",
      "wgs cells:  125\n",
      "-- in AS list:  []\n",
      "Final blacklist:  765\n",
      "Sanity check\n",
      "Blacklisted \"but\" annotated:  119\n",
      "Thereof, dropped/low qual:  118\n"
     ]
    }
   ],
   "source": [
    "import pandas\n",
    "import os\n",
    "import ftplib\n",
    "\n",
    "def keep_item(item):\n",
    "    if 'manifest' in item.lower():\n",
    "        return False\n",
    "    if 'readme' in item.lower():\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def traverse_remote_path(ftp_server, remote_url):\n",
    "    remote_listing = ftp_server.nlst(remote_url)\n",
    "    remote_files = []\n",
    "\n",
    "    for item in remote_listing:\n",
    "        # simplistic heuristic: if it has a file extension, it's a file\n",
    "        # works for intended use case\n",
    "        if len(item.split('.')) > 1:\n",
    "            # it's a file\n",
    "            remote_files.append(item)\n",
    "            continue\n",
    "        try:\n",
    "            sub_dir_listing = ftp_server.nlst(item)\n",
    "        except Exception as error:\n",
    "            continue\n",
    "        remote_files.extend(sub_dir_listing)\n",
    "\n",
    "    remote_files = [os.path.basename(f).split('_')[0] for f in remote_files]\n",
    "    remote_files = set(filter(keep_item, remote_files))\n",
    "\n",
    "    return sorted(remote_files)\n",
    "\n",
    "cache_folder = '/home/peter/work/code/github/ptrebert/project-diploid-assembly/annotation'\n",
    "cache_file = 'cache_ftp_sseq_fastq.txt'\n",
    "store_file = os.path.join(cache_folder, cache_file)\n",
    "\n",
    "if not os.path.isfile(store_file):\n",
    "    data_source = 'vol1/ftp/data_collections/HGSVC2/working/20200120_Strandseq/fastq'\n",
    "    server_url = 'ftp.1000genomes.ebi.ac.uk'\n",
    "    server = ftplib.FTP(server_url)\n",
    "    server.login()\n",
    "\n",
    "    sseq_fastq = traverse_remote_path(server, data_source)\n",
    "    with open(store_file, 'w') as dump:\n",
    "        _ = dump.write('\\n'.join(sseq_fastq))\n",
    "\n",
    "with open(store_file, 'r') as dump:\n",
    "    sseq_libs = set(dump.read().strip().split())\n",
    "\n",
    "print('FTP FASTQ libs: ', len(sseq_libs))\n",
    "\n",
    "selection = '../annotation/20200128_ASanders_QCselect_HGSVClibs.txt'\n",
    "controls = '../annotation/20200507_ASanders_100cell_controls.txt'\n",
    "wgs = '../annotation/20200507_ASanders_wgs_cells.txt'\n",
    "\n",
    "df = pandas.read_csv(selection, sep='\\t', comment='#')\n",
    "\n",
    "# Ashley's annotation is more restrictive as it targets\n",
    "# inversion analysis; for the clustering, it's just important\n",
    "# to get rid of the complete garbage\n",
    "high_qual = df.loc[df['score'] == 1, :]\n",
    "ok_qual = df.loc[((df['score'] == 0) & (df['reads'] > 50000)), :]\n",
    "low_qual = df.loc[((df['score'] == 0) & (df['reads'] <= 50000)), 'cell']\n",
    "\n",
    "accepted_libs = set(high_qual['cell'].values).union(set(ok_qual['cell'].values))\n",
    "print('OK libs ', len(accepted_libs))\n",
    "\n",
    "blacklist_from_ftp = sseq_libs.difference(accepted_libs)\n",
    "print('Blacklist ', len(blacklist_from_ftp))\n",
    "\n",
    "with open(controls, 'r') as annotation:\n",
    "    control_cells = set(annotation.read().strip().split())\n",
    "print('100c controls: ', len(control_cells))\n",
    "    \n",
    "accept_controls = []\n",
    "for c in control_cells:\n",
    "    if c in blacklist_from_ftp:\n",
    "        continue\n",
    "    elif c in accepted_libs:\n",
    "        accept_controls.append(c)\n",
    "    else:\n",
    "        print('-- Unknown: {}'.format(c))\n",
    "print('-- in AS list: ', accept_controls)\n",
    "\n",
    "with open(wgs, 'r') as annotation:\n",
    "    wgs_cells = set(annotation.read().strip().split())\n",
    "print('wgs cells: ', len(wgs_cells))\n",
    "    \n",
    "accept_wgs = []\n",
    "for w in wgs_cells:\n",
    "    if w in blacklist_from_ftp:\n",
    "        continue\n",
    "    elif w in accepted_libs:\n",
    "        accept_wgs.append(w)\n",
    "    else:\n",
    "        print('-- Unknown: {}'.format(w))\n",
    "print('-- in AS list: ', accept_wgs)\n",
    "\n",
    "final_blacklist = blacklist_from_ftp.union(control_cells, wgs_cells)\n",
    "print('Final blacklist: ', len(final_blacklist))\n",
    "\n",
    "# The overlap between Ashley's annotation and the blacklisted\n",
    "# libraries should be non-zero (e.g., because of the \"0\" quality\n",
    "# libs with less than 50000 reads). On the other hand, it should\n",
    "# also not be too large because the complete garbage is not part\n",
    "# of Ashley's annotation.\n",
    "\n",
    "print('Sanity check')\n",
    "sanity_check = final_blacklist.intersection(set(df['cell'].values))\n",
    "print('Blacklisted \"but\" annotated: ', len(sanity_check))\n",
    "print('Thereof, dropped/low qual: ', low_qual.shape[0])\n",
    "\n",
    "blacklist = '../annotation/hgsvc_blacklist.txt'\n",
    "\n",
    "with open(blacklist, 'w') as dump:\n",
    "    _ = dump.write('\\n'.join(sorted(final_blacklist)))\n",
    "\n",
    "    \n",
    "# update: Strand-seq data for NA20509 added\n",
    "# blacklist generated on 2020-05-13\n",
    "# MD5: ee7ccc87c35c8359b37da8e3f5559124\n",
    "    \n",
    "# blacklist generated on 2020-05-07\n",
    "# MD5: cc6f92724d97034523b68adadec1c9fa\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
